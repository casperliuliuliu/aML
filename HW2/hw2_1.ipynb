{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in 'D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_train':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "# import aML.HW2.other.model_structure as model_structure\n",
    "path = \"/Users/liushiwen/Desktop/大四下/hw2/test_data\"\n",
    "path = \"D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_train\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(f\"Files and directories in '{path}':\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.7734375\t0.4296875\t0.21875\t0.21875\n",
      "\n",
      "(128, 128, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAA70lEQVR4nO3SsUqCYRTG8QdpCIcKGhpd3JLadfVKqtG1oRuw7qALiMAl0CnEvZDGKHEvok9CP6hJzvkauoC35eWA/H/zy3n+wysBAAAAAAAAAAAAAAAA2dT7c/dpM2x/Z/DzfPm0Hm8H7bfeVz1JV3YSs3/8tupKarcegwI+7EzS3uJ7GRNwUV1L0qG7n4YETPxI0sHIirvdkICu30qNYWkvIfOSpuuiKP3LHqICmmOzUfvGzqMC/sw8GVDLGlBVySd5A/4hd0CZ+X7Cq+2H7nfckwFbWQvSf3DjP+H9MjTgsxx6zvsAAAAAAAAANsMvMtxFp2C/fUIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(f\"{path}/0000002.txt\", \"r\")\n",
    "print(f.read())\n",
    "img = Image.open(f'{path}/0121744.png')\n",
    "img = np.array(img)\n",
    "print(img.shape)\n",
    "img = Image.fromarray(img[:,:,2])\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(f'{path}/0121700.png')\n",
    "r, g, b, trash = img.split()\n",
    "\n",
    "r_array = np.array(r)\n",
    "g_array = np.array(g)\n",
    "b_array = np.array(b)\n",
    "\n",
    "# Check if all channels have the same array values\n",
    "are_channels_same = np.array_equal(r_array, g_array) and np.array_equal(g_array, b_array)\n",
    "are_channels_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.image_files = [f for f in os.listdir(data_folder) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_folder, self.image_files[idx])\n",
    "        image = read_image(image_path)\n",
    "        image = image[0:3].float()\n",
    "        # image = image.reshape(1, 128, 128)\n",
    "        \n",
    "        txt_file = os.path.splitext(self.image_files[idx])[0] + \".txt\"\n",
    "        txt_path = os.path.join(self.data_folder, txt_file)\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            class_label = int(first_line.split()[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, class_label\n",
    "    \n",
    "transform = transforms.Compose([])\n",
    "data_folder = path\n",
    "custom_dataset = CustomImageDataset(data_folder, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "def get_dataloaders(data_folder, transform, train_ratio, val_ratio, batch_size):\n",
    "    # Create a single merged dataset\n",
    "    train_dataset = CustomImageDataset(data_folder, transform)\n",
    "    val_dataset = CustomImageDataset(data_folder, transform)\n",
    "    test_dataset = CustomImageDataset(data_folder, transform)\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(test_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    print(\"--------- INDEX checking ---------\")\n",
    "    print(f\"Original: {indices[:5]}\")\n",
    "    random.shuffle(indices)\n",
    "    print(f\"Shuffled: {indices[:5]}\")\n",
    "    print(\"--------- INDEX shuffled ---------\\n\")\n",
    "\n",
    "    split_train = int(np.floor(train_ratio * num_train))\n",
    "    split_val = split_train + int(np.floor(val_ratio * (num_train-split_train)))\n",
    "    train_idx, val_idx, test_idx = indices[0:split_train], indices[split_train:split_val], indices[split_val:]\n",
    "    merge_dataset = Subset(train_dataset, train_idx)\n",
    "\n",
    "    train_loader = DataLoader(merge_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(Subset(val_dataset, val_idx), batch_size=batch_size)\n",
    "    test_loader = DataLoader(Subset(test_dataset, test_idx), batch_size=batch_size)\n",
    "    \n",
    "    # check dataset\n",
    "    print(f\"Total number of samples: {num_train} datapoints\")\n",
    "    print(f\"Number of train samples: {len(train_loader)} batches/ {len(train_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of val samples: {len(val_loader)} batches/ {len(val_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of test samples: {len(test_loader)} batches/ {len(test_loader.dataset)} datapoints\")\n",
    "    print(f\"Data Transform: {transform}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        \"test\": test_loader,\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- INDEX checking ---------\n",
      "Original: [0, 1, 2, 3, 4]\n",
      "Shuffled: [67332, 47905, 40562, 81512, 86722]\n",
      "--------- INDEX shuffled ---------\n",
      "\n",
      "Total number of samples: 97396 datapoints\n",
      "Number of train samples: 4 batches/ 973 datapoints\n",
      "Number of val samples: 189 batches/ 48211 datapoints\n",
      "Number of test samples: 189 batches/ 48212 datapoints\n",
      "Data Transform: Compose(\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaders = get_dataloaders(data_folder, transform, 0.01, 0.5, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus on the 3rd problem\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    filename = \"hw2-1-3-MAR23.txt\"\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"OFFICIAL START, Focus on the 3rd problem\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, model_name):\n",
    "    # pprint(f\"test modify Resnet18 {model_name}\", True)\n",
    "    model_parameters_amount = count_parameters(model)\n",
    "    pprint(f\"model total parameters: {model_parameters_amount:,}\")\n",
    "\n",
    "    model = model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr= 0.005\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.2)\n",
    "    pprint(f\"learning rate={lr}\")\n",
    "    iteration = 0\n",
    "    epochs = 1\n",
    "    start = time.time()\n",
    "    phases = ['train']\n",
    "    # return \n",
    "    for epoch in range(epochs):\n",
    "        for phase in phases:\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            correct_top3_predictions = 0\n",
    "            total_samples = 0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            for images, labels in tqdm(loaders[phase]): # Iterate over data.\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train': # backward + optimize only if in training phase\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "                _, top3_preds = outputs.topk(3, 1, True, True)\n",
    "                correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "\n",
    "                total_samples += labels.size(0)\n",
    "                iteration += 1\n",
    "\n",
    "            avg_loss = running_loss / total_samples\n",
    "            top1_accuracy = correct_predictions / total_samples * 100\n",
    "            top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "            pprint(f\"Epoch [{epoch+1}/{epochs}], phase: {phase}, samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    pprint(f\"Elapsed time: {duration} seconds\")\n",
    "    return\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(f'{model_name}.pt') # Save\n",
    "    pprint(f\"weight saved as: {model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model total parameters: 11,689,512\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.60it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0384, Top-1 Accuracy: 1.34%, Top-3 Accuracy: 3.60%\n",
      "Elapsed time: 1.1196253299713135 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 46.4M/97.8M [00:05<00:05, 10.7MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 10.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model total parameters: 25,557,032\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0295, Top-1 Accuracy: 0.00%, Top-3 Accuracy: 0.00%\n",
      "Elapsed time: 3.528817892074585 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\resnet101-cd907fc2.pth\n",
      "100%|██████████| 171M/171M [00:16<00:00, 10.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model total parameters: 44,549,160\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0296, Top-1 Accuracy: 0.82%, Top-3 Accuracy: 1.44%\n",
      "Elapsed time: 14.052119255065918 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\resnet152-f82ba261.pth\n",
      "100%|██████████| 230M/230M [00:26<00:00, 9.23MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model total parameters: 60,192,808\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:18<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0299, Top-1 Accuracy: 0.00%, Top-3 Accuracy: 0.10%\n",
      "Elapsed time: 18.755255222320557 seconds\n",
      "model total parameters: 28,288,354\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:12<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0286, Top-1 Accuracy: 2.57%, Top-3 Accuracy: 7.50%\n",
      "Elapsed time: 12.918222904205322 seconds\n",
      "model total parameters: 49,606,258\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:27<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0265, Top-1 Accuracy: 4.73%, Top-3 Accuracy: 10.07%\n",
      "Elapsed time: 27.675967931747437 seconds\n",
      "model total parameters: 87,768,224\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:47<00:00, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], phase: train, samples: 973, Loss: 0.0269, Top-1 Accuracy: 4.01%, Top-3 Accuracy: 8.63%\n",
      "Elapsed time: 47.90890598297119 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model_lists = {\n",
    "    'resnet18': lambda: models.resnet18(weights=models.ResNet18_Weights.DEFAULT),\n",
    "    'resnet50': lambda: models.resnet50(weights=models.ResNet50_Weights.DEFAULT),\n",
    "    'resnet101': lambda: models.resnet101(weights=models.ResNet101_Weights.DEFAULT),\n",
    "    'resnet152': lambda: models.resnet152(weights=models.ResNet152_Weights.DEFAULT),\n",
    "    'swin_v2_t': lambda: models.swin_t(weights=models.Swin_T_Weights.DEFAULT),\n",
    "    'swin_v2_s': lambda: models.swin_s(weights=models.Swin_S_Weights.DEFAULT),\n",
    "    'swin_v2_b': lambda: models.swin_b(weights=models.Swin_B_Weights.DEFAULT),\n",
    "}\n",
    "\n",
    "model_names = [\n",
    "    'resnet18',\n",
    "    'resnet50',\n",
    "    'resnet101',\n",
    "    'resnet152',\n",
    "    'swin_v2_t',\n",
    "    'swin_v2_s',\n",
    "    'swin_v2_b',\n",
    "]\n",
    "for model_name in model_names:\n",
    "    model = model_lists[model_name]()\n",
    "    train(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(output_list):\n",
    "    stacked_outputs = torch.stack(output_list)\n",
    "    avg_probs = torch.mean(stacked_outputs, dim=0)\n",
    "    \n",
    "    return avg_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval(model_list):\n",
    "    for model in model_list:\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    start = time.time()\n",
    "    phases = ['val']\n",
    "    num_class = 10\n",
    "    for phase in phases:\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        correct_top3_predictions = 0\n",
    "        total_samples = 0\n",
    "        confus = torch.zeros(num_class, num_class,dtype=int)            \n",
    "        for images, labels in tqdm(loaders[phase]): # Iterate over data.\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            model_outputs = []\n",
    "            for model in model_list:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(images)\n",
    "                    model_outputs.append(outputs)\n",
    "            vote_outputs = majority_voting(model_outputs)\n",
    "            loss = criterion(vote_outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(vote_outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            _, top3_preds = outputs.topk(3, 1, True, True)\n",
    "            correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            for ii in range(len(predicted)):\n",
    "                confus[ labels.data[ii] ][ predicted[ii] ]+=1\n",
    "\n",
    "        avg_loss = running_loss / total_samples\n",
    "        top1_accuracy = correct_predictions / total_samples * 100\n",
    "        top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "        pprint(f\"Phase: {phase}, samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "        for ii in range(num_class) :\n",
    "            pprint(f\"class {ii}:{confus.numpy()[ii]}\")\n",
    "        # pprint(confus)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    pprint(f\"Elapsed time: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: val, samples: 487, Loss: 0.0006, Top-1 Accuracy: 95.89%, Top-3 Accuracy: 99.59%\n",
      "class 0:[42  0  0  0  0  0  0  0  0  0]\n",
      "class 1:[ 1 56  0  0  0  0  0  0  0  0]\n",
      "class 2:[ 0  0 40  0  0  0  0  0  2  1]\n",
      "class 3:[ 1  0  0 36  0  0  0  1  0  0]\n",
      "class 4:[ 0  0  0  0 51  0  0  0  0  1]\n",
      "class 5:[ 0  1  0  0  0 51  0  0  2  0]\n",
      "class 6:[ 0  0  0  0  0  0 48  0  0  0]\n",
      "class 7:[ 1  0  0  0  0  0  0 56  0  2]\n",
      "class 8:[ 6  0  0  0  0  0  0  0 47  1]\n",
      "class 9:[ 0  0  0  0  0  0  0  0  0 40]\n",
      "Elapsed time: 0.4988720417022705 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "path = \"D:\\\\Casper\\\\aML\\\\HW2\\\\aML\\\\\"\n",
    "model_list = [\n",
    "    # torch.jit.load(f'{path}R6_btnk_4ch8n4.pt'),\n",
    "    torch.jit.load(f'{path}R6_btnk_ch8(hw2).pt'),\n",
    "    # torch.jit.load(f'{path}resnet6.pt'),\n",
    "    # models.resnet18(weights=True),\n",
    "    # models.resnet50(weights=True),\n",
    "    # models.resnet101(weights=True),\n",
    "    # models.resnet152(weights=True),\n",
    "    # models.swin_v2_t(weights=True),\n",
    "    # models.swin_v2_s(weights=True),\n",
    "    # models.swin_v2_b(weights=True),\n",
    "    # models.vit_h_14(weights=models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1),\n",
    "]\n",
    "\n",
    "model_name = [\n",
    "    'resnet18',\n",
    "    # 'resnet50',\n",
    "    # 'resnet101',\n",
    "    # 'resnet152',\n",
    "    # 'swin_v2_t',\n",
    "    # 'swin_v2_s',\n",
    "    # 'swin_v2_b',\n",
    "    # 'vit_h_14',\n",
    "]\n",
    "eval(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
