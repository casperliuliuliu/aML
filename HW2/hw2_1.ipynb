{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in 'D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_train':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import model_structure\n",
    "import torchvision.models as models\n",
    "path = \"/Users/liushiwen/Desktop/大四下/hw2/test_data\"\n",
    "path = \"D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_train\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(f\"Files and directories in '{path}':\")\n",
    "# for item in dir_list:\n",
    "#     print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.7734375\t0.4296875\t0.21875\t0.21875\n",
      "\n",
      "(128, 128, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAA70lEQVR4nO3SsUqCYRTG8QdpCIcKGhpd3JLadfVKqtG1oRuw7qALiMAl0CnEvZDGKHEvok9CP6hJzvkauoC35eWA/H/zy3n+wysBAAAAAAAAAAAAAAAA2dT7c/dpM2x/Z/DzfPm0Hm8H7bfeVz1JV3YSs3/8tupKarcegwI+7EzS3uJ7GRNwUV1L0qG7n4YETPxI0sHIirvdkICu30qNYWkvIfOSpuuiKP3LHqICmmOzUfvGzqMC/sw8GVDLGlBVySd5A/4hd0CZ+X7Cq+2H7nfckwFbWQvSf3DjP+H9MjTgsxx6zvsAAAAAAAAANsMvMtxFp2C/fUIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(f\"{path}/0000002.txt\", \"r\")\n",
    "print(f.read())\n",
    "img = Image.open(f'{path}/0121744.png')\n",
    "img = np.array(img)\n",
    "print(img.shape)\n",
    "img = Image.fromarray(img[:,:,2])\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(f'{path}/0121700.png')\n",
    "r, g, b, trash = img.split()\n",
    "\n",
    "r_array = np.array(r)\n",
    "g_array = np.array(g)\n",
    "b_array = np.array(b)\n",
    "\n",
    "# Check if all channels have the same array values\n",
    "are_channels_same = np.array_equal(r_array, g_array) and np.array_equal(g_array, b_array)\n",
    "are_channels_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.image_files = [f for f in os.listdir(data_folder) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_folder, self.image_files[idx])\n",
    "        image = read_image(image_path)\n",
    "        image = image[0:3].float()\n",
    "        # image = image.reshape(1, 128, 128)\n",
    "        \n",
    "        txt_file = os.path.splitext(self.image_files[idx])[0] + \".txt\"\n",
    "        txt_path = os.path.join(self.data_folder, txt_file)\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            class_label = int(first_line.split()[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, class_label\n",
    "    \n",
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, data_folder, transform=None):\n",
    "#         self.data_folder = data_folder\n",
    "#         self.transform = transform\n",
    "#         self.classes = self._find_classes(data_folder)\n",
    "#         self.samples = self._make_dataset(data_folder)\n",
    "\n",
    "#     def _find_classes(self, dir):\n",
    "#         \"\"\"\n",
    "#         Finds the class folders in a dataset.\n",
    "        \n",
    "#         Returns:\n",
    "#             A mapping from class names to class indices.\n",
    "#         \"\"\"\n",
    "#         # Assuming class names are in the filenames before an underscore '_'\n",
    "#         class_names = sorted({file.split(\"_\")[0] for file in os.listdir(dir) if file.endswith(\".png\")})\n",
    "#         class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "#         return class_to_idx\n",
    "    \n",
    "#     def _make_dataset(self, dir):\n",
    "#         \"\"\"\n",
    "#         Creates a list of samples from the dataset directory.\n",
    "#         \"\"\"\n",
    "#         images = [f for f in os.listdir(dir) if f.endswith(\".png\")]\n",
    "#         samples = []\n",
    "#         for img_name in images:\n",
    "#             class_name = img_name.split(\"_\")[0]\n",
    "#             class_idx = self.classes[class_name]\n",
    "#             samples.append((os.path.join(dir, img_name), class_idx))\n",
    "#         return samples\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path, label = self.samples[idx]\n",
    "#         image = read_image(image_path)\n",
    "#         image = image[0:1].float()  # Assuming you still want to do this\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return image, label\n",
    "transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                ])\n",
    "data_folder = path\n",
    "custom_dataset = CustomImageDataset(data_folder, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "def get_dataloaders(data_folder, transform, train_ratio, val_ratio, batch_size):\n",
    "    # Create a single merged dataset\n",
    "    train_dataset = CustomImageDataset(data_folder, transform)\n",
    "    val_dataset = CustomImageDataset(data_folder, transform)\n",
    "    test_dataset = CustomImageDataset(data_folder, transform)\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(test_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    print(\"--------- INDEX checking ---------\")\n",
    "    print(f\"Original: {indices[:5]}\")\n",
    "    random.shuffle(indices)\n",
    "    print(f\"Shuffled: {indices[:5]}\")\n",
    "    print(\"--------- INDEX shuffled ---------\\n\")\n",
    "\n",
    "    split_train = int(np.floor(train_ratio * num_train))\n",
    "    split_val = split_train + int(np.floor(val_ratio * (num_train-split_train)))\n",
    "    train_idx, val_idx, test_idx = indices[0:split_train], indices[split_train:split_val], indices[split_val:]\n",
    "    merge_dataset = Subset(train_dataset, train_idx)\n",
    "\n",
    "    train_loader = DataLoader(merge_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(Subset(val_dataset, val_idx), batch_size=batch_size)\n",
    "    test_loader = DataLoader(Subset(test_dataset, test_idx), batch_size=batch_size)\n",
    "    \n",
    "    # check dataset\n",
    "    print(f\"Total number of samples: {num_train} datapoints\")\n",
    "    print(f\"Number of train samples: {len(train_loader)} batches/ {len(train_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of val samples: {len(val_loader)} batches/ {len(val_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of test samples: {len(test_loader)} batches/ {len(test_loader.dataset)} datapoints\")\n",
    "    print(f\"Data Transform: {transform}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        \"test\": test_loader,\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- INDEX checking ---------\n",
      "Original: [0, 1, 2, 3, 4]\n",
      "Shuffled: [85578, 65585, 59926, 40240, 24393]\n",
      "--------- INDEX shuffled ---------\n",
      "\n",
      "Total number of samples: 97396 datapoints\n",
      "Number of train samples: 229 batches/ 58437 datapoints\n",
      "Number of val samples: 77 batches/ 19479 datapoints\n",
      "Number of test samples: 77 batches/ 19480 datapoints\n",
      "Data Transform: Compose(\n",
      "    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaders = get_dataloaders(data_folder, transform, 0.6, 0.5, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = loaders['train']\n",
    "# val_loader = loaders['val']\n",
    "# test_loader = loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(custom_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_loader = DataLoader(custom_dataset, batch_size=1, shuffle=True)\n",
    "# # test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "# print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "class mod_resnet(nn.Module):\n",
    "    def __init__(self, block, layers, channel_num_list, num_classes=1000):\n",
    "        super(mod_resnet, self).__init__()\n",
    "        self.in_channels = channel_num_list[0]\n",
    "        self.conv1 = nn.Conv2d(3, channel_num_list[0], kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channel_num_list[0])\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, channel_num_list[1], layers[0])\n",
    "        # self.layer2 = self._make_layer(block, channel_num_list[2], layers[1], stride=2)\n",
    "        # self.layer3 = self._make_layer(block, channel_num_list[3], layers[2], stride=2)\n",
    "        # self.layer4 = self._make_layer(block, channel_num_list[4], layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(channel_num_list[-1] * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        # x = self.layer2(x)\n",
    "        # x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modify_resnet18(model):\n",
    "#     # Load a pretrained ResNet-18 model\n",
    "#     print(count_parameters(model))\n",
    "    \n",
    "#     # Remove the 3rd and 4th layer groups\n",
    "#     model.layer2 = nn.Identity()\n",
    "#     model.layer3 = nn.Identity()\n",
    "#     model.layer4 = nn.Flatten()\n",
    "\n",
    "#     num_features = 64 * 56 * 56\n",
    "#     model.fc = nn.Linear(num_features, 10)  # Example: 1000 classes, adjust as necessary\n",
    "#     print(count_parameters(model))\n",
    "\n",
    "#     return model\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize small resnet\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    filename = \"record_BottleNeck_4.txt\"\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"optimize small resnet\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = \"C:/Users/User/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\"\n",
    "# model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "# model = models.resnet18()\n",
    "# model = modify_resnet18(model)\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# model.load_state_dict(torch.load(weight))\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# model  = model_structure.SimpleCNN()\n",
    "import time\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "def train(model, model_name):\n",
    "    pprint(f\"test modify Resnet18 {model_name}\", True)\n",
    "    model_parameters_amount = count_parameters(model)\n",
    "    pprint(f\"model total parameters: {model_parameters_amount:,}\")\n",
    "\n",
    "    model = model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr= 0.005\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    pprint(f\"learning rate={lr}\")\n",
    "    iteration = 0\n",
    "    epochs = 20\n",
    "    start = time.time()\n",
    "    phases = ['train','val']\n",
    "    for epoch in range(epochs):\n",
    "        for phase in phases:\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            correct_top3_predictions = 0\n",
    "            total_samples = 0\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            for images, labels in tqdm(loaders[phase]): # Iterate over data.\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train': # backward + optimize only if in training phase\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Convert outputs to predicted class by selecting the class with the highest score\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                # Accumulate the number of correct predictions\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "                _, top3_preds = outputs.topk(3, 1, True, True)\n",
    "                correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "\n",
    "                total_samples += labels.size(0)\n",
    "                iteration += 1\n",
    "                # if iteration % 20 == 0:\n",
    "                #     print(iteration)\n",
    "            avg_loss = running_loss / total_samples\n",
    "            top1_accuracy = correct_predictions / total_samples * 100\n",
    "            top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "            pprint(f\"Epoch [{epoch+1}/{epochs}], phase: {phase}, samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    pprint(f\"Elapsed time: {duration} seconds\")\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(f'{model_name}.pt') # Save\n",
    "    pprint(f\"weight saved as: {model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test modify Resnet18 R6_btnk_ch2\n",
      "model total parameters: 592\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/229 [00:00<00:47,  4.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:42<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: train, samples: 58437, Loss: 0.0080, Top-1 Accuracy: 21.64%, Top-3 Accuracy: 52.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: val, samples: 19479, Loss: 0.0073, Top-1 Accuracy: 27.77%, Top-3 Accuracy: 64.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:41<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: train, samples: 58437, Loss: 0.0068, Top-1 Accuracy: 33.25%, Top-3 Accuracy: 68.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:13<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: val, samples: 19479, Loss: 0.0070, Top-1 Accuracy: 35.25%, Top-3 Accuracy: 67.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: train, samples: 58437, Loss: 0.0061, Top-1 Accuracy: 43.05%, Top-3 Accuracy: 77.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: val, samples: 19479, Loss: 0.0059, Top-1 Accuracy: 47.08%, Top-3 Accuracy: 80.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: train, samples: 58437, Loss: 0.0054, Top-1 Accuracy: 48.50%, Top-3 Accuracy: 82.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:13<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: val, samples: 19479, Loss: 0.0053, Top-1 Accuracy: 50.55%, Top-3 Accuracy: 83.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: train, samples: 58437, Loss: 0.0050, Top-1 Accuracy: 52.84%, Top-3 Accuracy: 85.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: val, samples: 19479, Loss: 0.0058, Top-1 Accuracy: 46.63%, Top-3 Accuracy: 80.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:41<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: train, samples: 58437, Loss: 0.0047, Top-1 Accuracy: 55.92%, Top-3 Accuracy: 87.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: val, samples: 19479, Loss: 0.0048, Top-1 Accuracy: 53.20%, Top-3 Accuracy: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], phase: train, samples: 58437, Loss: 0.0045, Top-1 Accuracy: 58.15%, Top-3 Accuracy: 88.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], phase: val, samples: 19479, Loss: 0.0052, Top-1 Accuracy: 50.59%, Top-3 Accuracy: 83.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], phase: train, samples: 58437, Loss: 0.0043, Top-1 Accuracy: 59.76%, Top-3 Accuracy: 89.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], phase: val, samples: 19479, Loss: 0.0044, Top-1 Accuracy: 58.05%, Top-3 Accuracy: 89.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:39<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], phase: train, samples: 58437, Loss: 0.0042, Top-1 Accuracy: 61.14%, Top-3 Accuracy: 90.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], phase: val, samples: 19479, Loss: 0.0046, Top-1 Accuracy: 57.76%, Top-3 Accuracy: 88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:38<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], phase: train, samples: 58437, Loss: 0.0041, Top-1 Accuracy: 62.30%, Top-3 Accuracy: 90.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], phase: val, samples: 19479, Loss: 0.0041, Top-1 Accuracy: 63.36%, Top-3 Accuracy: 91.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:41<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], phase: train, samples: 58437, Loss: 0.0040, Top-1 Accuracy: 63.42%, Top-3 Accuracy: 91.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], phase: val, samples: 19479, Loss: 0.0041, Top-1 Accuracy: 64.01%, Top-3 Accuracy: 90.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], phase: train, samples: 58437, Loss: 0.0039, Top-1 Accuracy: 64.46%, Top-3 Accuracy: 91.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:13<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], phase: val, samples: 19479, Loss: 0.0041, Top-1 Accuracy: 63.95%, Top-3 Accuracy: 90.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:41<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], phase: train, samples: 58437, Loss: 0.0038, Top-1 Accuracy: 65.56%, Top-3 Accuracy: 92.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], phase: val, samples: 19479, Loss: 0.0043, Top-1 Accuracy: 60.91%, Top-3 Accuracy: 89.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:38<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], phase: train, samples: 58437, Loss: 0.0038, Top-1 Accuracy: 66.63%, Top-3 Accuracy: 92.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:13<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], phase: val, samples: 19479, Loss: 0.0038, Top-1 Accuracy: 67.53%, Top-3 Accuracy: 92.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:38<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], phase: train, samples: 58437, Loss: 0.0037, Top-1 Accuracy: 67.77%, Top-3 Accuracy: 92.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], phase: val, samples: 19479, Loss: 0.0037, Top-1 Accuracy: 68.59%, Top-3 Accuracy: 92.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:39<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], phase: train, samples: 58437, Loss: 0.0036, Top-1 Accuracy: 68.56%, Top-3 Accuracy: 93.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], phase: val, samples: 19479, Loss: 0.0037, Top-1 Accuracy: 68.58%, Top-3 Accuracy: 92.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:39<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], phase: train, samples: 58437, Loss: 0.0035, Top-1 Accuracy: 69.20%, Top-3 Accuracy: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], phase: val, samples: 19479, Loss: 0.0037, Top-1 Accuracy: 68.18%, Top-3 Accuracy: 92.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], phase: train, samples: 58437, Loss: 0.0035, Top-1 Accuracy: 69.80%, Top-3 Accuracy: 93.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], phase: val, samples: 19479, Loss: 0.0037, Top-1 Accuracy: 68.40%, Top-3 Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:42<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], phase: train, samples: 58437, Loss: 0.0034, Top-1 Accuracy: 70.64%, Top-3 Accuracy: 93.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:12<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], phase: val, samples: 19479, Loss: 0.0036, Top-1 Accuracy: 69.60%, Top-3 Accuracy: 92.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:42<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], phase: train, samples: 58437, Loss: 0.0034, Top-1 Accuracy: 71.63%, Top-3 Accuracy: 93.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], phase: val, samples: 19479, Loss: 0.0035, Top-1 Accuracy: 69.94%, Top-3 Accuracy: 92.98%\n",
      "Elapsed time: 1058.6547610759735 seconds\n",
      "weight saved as: R6_btnk_ch2.pt\n",
      "test modify Resnet18 R6_btnk_ch1\n",
      "model total parameters: 266\n",
      "learning rate=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: train, samples: 58437, Loss: 0.0086, Top-1 Accuracy: 19.24%, Top-3 Accuracy: 48.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], phase: val, samples: 19479, Loss: 0.0081, Top-1 Accuracy: 22.49%, Top-3 Accuracy: 57.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:39<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: train, samples: 58437, Loss: 0.0078, Top-1 Accuracy: 23.44%, Top-3 Accuracy: 60.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], phase: val, samples: 19479, Loss: 0.0076, Top-1 Accuracy: 26.53%, Top-3 Accuracy: 64.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:40<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: train, samples: 58437, Loss: 0.0072, Top-1 Accuracy: 26.93%, Top-3 Accuracy: 67.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], phase: val, samples: 19479, Loss: 0.0077, Top-1 Accuracy: 21.12%, Top-3 Accuracy: 56.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:38<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: train, samples: 58437, Loss: 0.0068, Top-1 Accuracy: 29.96%, Top-3 Accuracy: 71.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], phase: val, samples: 19479, Loss: 0.0069, Top-1 Accuracy: 29.08%, Top-3 Accuracy: 70.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:39<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: train, samples: 58437, Loss: 0.0067, Top-1 Accuracy: 31.53%, Top-3 Accuracy: 73.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], phase: val, samples: 19479, Loss: 0.0067, Top-1 Accuracy: 31.59%, Top-3 Accuracy: 73.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: train, samples: 58437, Loss: 0.0066, Top-1 Accuracy: 32.26%, Top-3 Accuracy: 74.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:11<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], phase: val, samples: 19479, Loss: 0.0076, Top-1 Accuracy: 19.64%, Top-3 Accuracy: 58.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:43<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], phase: train, samples: 58437, Loss: 0.0065, Top-1 Accuracy: 32.71%, Top-3 Accuracy: 75.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 62/77 [00:09<00:02,  6.38it/s]"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    # mod_resnet(Bottleneck, [1, 0,0,0], channel_num=64, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 0,0,0], channel_num=16, num_classes=10),\n",
    "    # mod_resnet(BasicBlock, [2, 0,0,0], channel_num=32, num_classes=10),\n",
    "    # mod_resnet(BasicBlock, [2, 0,0,0], channel_num=16, num_classes=10),\n",
    "    # mod_resnet(BasicBlock, [2, 0,0,0], channel_num=4, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [2, 0,0,0], channel_num=16, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [2, 0,0,0], channel_num=4, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [4, 0,0,0], channel_num=2, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [4, 0,0,0], channel_num=4, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [2, 0,0,0], channel_num=8, num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [2, 2,0,0], channel_num_list=[8, 4], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1,1,1], channel_num_list=[4,4,8, 8], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [2, 0, 0, 0], channel_num_list=[8,4], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[8,8,4], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[8,4,8], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[4,8,4], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[4,4,8], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[4,8,8], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[8,4,4], num_classes=10),\n",
    "    # mod_resnet(Bottleneck, [1, 1, 0, 0], channel_num_list=[8,4,8], num_classes=10),\n",
    "    mod_resnet(Bottleneck, [2, 0, 0, 0], channel_num_list=[2,2], num_classes=10),\n",
    "    mod_resnet(Bottleneck, [2, 0, 0, 0], channel_num_list=[1,1], num_classes=10),\n",
    "\n",
    "]\n",
    "\n",
    "model_name = [\n",
    "    # \"resnet4_btnk\",\n",
    "    # \"resnet4_btnk_ch16\",\n",
    "    # \"resnet6_ch32\",\n",
    "    # \"resnet6_ch16\",\n",
    "    # \"resnet6_ch4\",\n",
    "    # \"resnet6_btnk_ch16\",\n",
    "    # \"resnet6_btnk_ch4\",\n",
    "    # \"resnet10_btnk_ch2\",\n",
    "    # \"resnet10_btnk_ch4\",\n",
    "    # \"resnet6_btnk_ch8\",\n",
    "    # \"resnet10_btnk_ch4n8\",\n",
    "    # \"resnet10_btnk_ch4n4n8n8\",\n",
    "    # \"R6_btnk_8ch4\"\n",
    "    # \"R6_btnk_ch8n4\",\n",
    "    # \"R6_btnk_8ch4n8\",\n",
    "    # \"R6_btnk_4ch8n4\",\n",
    "    # \"R6_btnk_ch4n8\",\n",
    "    # \"R6_btnk_4ch8\",\n",
    "    # \"R6_btnk_8ch4\",\n",
    "    # \"R6_btnk_ch8(2)\",\n",
    "    \"R6_btnk_ch2\",\n",
    "    \"R6_btnk_ch1\",\n",
    "]\n",
    "for ii in range(len(model_name)):\n",
    "    train(model_list[ii], model_name[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.jit.load('R6_btnk_8ch4.pt')\n",
    "print(count_parameters(model))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_test\"\n",
    "\n",
    "test_dataset = CustomImageDataset(data_folder, transform)\n",
    "\n",
    "test_loader = DataLoader(custom_dataset, batch_size=128)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomImageDataset' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m [test_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mclasses[pred] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predicted]  \u001b[38;5;66;03m# Convert to class names if applicable\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, pred_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(filenames, predicted_classes):\n\u001b[0;32m     23\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([filename, pred_class])\n",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m [\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m[pred] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predicted]  \u001b[38;5;66;03m# Convert to class names if applicable\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, pred_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(filenames, predicted_classes):\n\u001b[0;32m     23\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([filename, pred_class])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomImageDataset' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import csv\n",
    "\n",
    "# # Assuming model is your trained model and test_loader is your DataLoader for the test dataset\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Path to save the CSV file\n",
    "# output_csv_path = 'test_predictions.csv'\n",
    "\n",
    "# with torch.no_grad():  # No need to track gradients for validation\n",
    "#     with open(output_csv_path, mode='w', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow(['filename', 'class'])  # Write the header row\n",
    "\n",
    "#         for images, labels, filenames in test_loader:  # Assuming filenames are provided\n",
    "#             images = images.cuda()\n",
    "#             outputs = model(images)\n",
    "\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             predicted_classes = [test_loader.dataset.classes[pred] for pred in predicted]  # Convert to class names if applicable\n",
    "\n",
    "#             for filename, pred_class in zip(filenames, predicted_classes):\n",
    "#                 writer.writerow([filename, pred_class])\n",
    "\n",
    "# print(f\"Results saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch [1/10], Loss: 1.7137, Accuracy: 37.24%\n",
      "Epoch [2/10], Loss: 1.5531, Accuracy: 43.10%\n",
      "Epoch [3/10], Loss: 1.5096, Accuracy: 44.43%\n",
      "Epoch [4/10], Loss: 1.4768, Accuracy: 45.74%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     53\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 64 * 64)  # Flatten the feature maps\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load CIFAR-10 dataset (you can replace this with your own dataset)\n",
    "transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                transforms.ToTensor()])\n",
    "train_dataset = CIFAR10(root=\"D:\\Casper\\OTHER\\Data\\cifar\", train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN()\n",
    "model = model.cuda()\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (you can adjust the number of epochs)\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "        \n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Convert outputs to predicted class by selecting the class with the highest score\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # Accumulate the number of correct predictions\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        # Accumulate the total number of samples seen\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Optional: break here if you want to test with just the first batch\n",
    "        # break\n",
    "\n",
    "    # Calculate average loss and accuracy over the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "        # break\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5898, -0.3613,  2.0499, -0.5059, -0.5985]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5898,  0.6387,  3.0499,  0.4941,  0.4015]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel()\n",
    "x = torch.randn(1, 10)\n",
    "print(model(x))\n",
    "# Define a new forward function\n",
    "def new_forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    return x +1 # Just an example modification\n",
    "\n",
    "# Assign the new forward function to the model\n",
    "model.forward = new_forward.__get__(model, SimpleModel)\n",
    "\n",
    "# Test the modified model\n",
    "print(model(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11689512\n",
      "659274\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Identity()\n",
      "  (layer3): Identity()\n",
      "  (layer4): Identity()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=50176, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "def modify_resnet18():\n",
    "    # Load a pretrained ResNet-18 model\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    print(count_parameters(model))\n",
    "    \n",
    "    # Remove the 3rd and 4th layer groups\n",
    "    model.layer2 = nn.Identity()\n",
    "    model.layer3 = nn.Identity()\n",
    "    model.layer4 = nn.Identity()\n",
    "\n",
    "    # Assuming the output of layer2 is 128 channels, and considering the \n",
    "    # downsampling, calculate the size of the output feature map.\n",
    "    # For a 224x224 input image, after the initial conv and maxpool, the size is 56x56.\n",
    "    # After layer1, it remains 56x56 (since stride=1 in ResNet-18's layer1).\n",
    "    # After layer2, due to downsampling, the size is 28x28.\n",
    "    # Thus, the output size after layer2 for a 224x224 input is 128x28x28.\n",
    "    # However, if your input size is different (e.g., MNIST images), you'll need to adjust this calculation.\n",
    "    num_features = 64 * 28 * 28  # Adjust this based on your actual input size\n",
    "    # Modify the fc layer to match this size\n",
    "    model.fc = nn.Linear(num_features, 10)  # Example: 1000 classes, adjust as necessary\n",
    "    print(count_parameters(model))\n",
    "\n",
    "    return model\n",
    "# Modify the ResNet-18\n",
    "modified_model = modify_resnet18()\n",
    "\n",
    "# Print the modified model summary to verify changes\n",
    "print(modified_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84170\n"
     ]
    }
   ],
   "source": [
    "model = torch.jit.load('D:\\\\Casper\\\\aML\\\\HW2\\\\aML\\\\resnet4.pt')\n",
    "# print(model)\n",
    "print(count_parameters(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
