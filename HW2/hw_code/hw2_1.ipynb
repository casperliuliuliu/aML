{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import csv\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.image_files = [f for f in os.listdir(data_folder) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_folder, self.image_files[idx])\n",
    "        image = read_image(image_path)\n",
    "        image = image[0:3].float()\n",
    "        # image = image.reshape(1, 128, 128)\n",
    "        \n",
    "        txt_file = os.path.splitext(self.image_files[idx])[0] + \".txt\"\n",
    "        txt_path = os.path.join(self.data_folder, txt_file)\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            class_label = int(first_line.split()[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, class_label\n",
    "    \n",
    "\n",
    "class CustomImageDataset_test(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.image_files = [f for f in os.listdir(data_folder) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_folder, self.image_files[idx])\n",
    "        image_name = self.image_files[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = image[0:3].float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataloaders(data_folder, transform, train_ratio, val_ratio, batch_size, shuffle_flag=True, train_data=True):\n",
    "    if train_data:\n",
    "        # Create a single merged dataset\n",
    "        train_dataset = CustomImageDataset(data_folder, transform)\n",
    "        val_dataset = CustomImageDataset(data_folder, transform)\n",
    "        test_dataset = CustomImageDataset(data_folder, transform)\n",
    "    else:\n",
    "        train_dataset = CustomImageDataset_test(data_folder, transform)\n",
    "        val_dataset = CustomImageDataset_test(data_folder, transform)\n",
    "        test_dataset = CustomImageDataset_test(data_folder, transform)\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(test_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    print(\"--------- INDEX checking ---------\")\n",
    "    print(f\"Original: {indices[:5]}\")\n",
    "    if shuffle_flag:\n",
    "        random.shuffle(indices)\n",
    "    print(f\"Shuffled: {indices[:5]}\")\n",
    "    print(\"--------- INDEX shuffled ---------\\n\")\n",
    "\n",
    "    split_train = int(np.floor(train_ratio * num_train))\n",
    "    split_val = split_train + int(np.floor(val_ratio * (num_train-split_train)))\n",
    "    train_idx, val_idx, test_idx = indices[0:split_train], indices[split_train:split_val], indices[split_val:]\n",
    "    merge_dataset = Subset(train_dataset, train_idx)\n",
    "\n",
    "    train_loader = DataLoader(merge_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(Subset(val_dataset, val_idx), batch_size=batch_size)\n",
    "    test_loader = DataLoader(Subset(test_dataset, test_idx), batch_size=batch_size)\n",
    "    \n",
    "    # check dataset\n",
    "    print(f\"Total number of samples: {num_train} datapoints\")\n",
    "    print(f\"Number of train samples: {len(train_loader)} batches/ {len(train_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of val samples: {len(val_loader)} batches/ {len(val_loader.dataset)} datapoints\")\n",
    "    print(f\"Number of test samples: {len(test_loader)} batches/ {len(test_loader.dataset)} datapoints\")\n",
    "    print(f\"Data Transform: {transform}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    dataloaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        \"test\": test_loader,\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_num = 0\n",
    "    for parameter in model.parameters():\n",
    "        if parameter.requires_grad:\n",
    "            total_num += parameter.numel() \n",
    "    return total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(output_list):\n",
    "    stacked_outputs = torch.stack(output_list)\n",
    "    avg_probs = torch.mean(stacked_outputs, dim=0)\n",
    "    \n",
    "    return avg_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_list, data_loader):\n",
    "    for model in model_list:\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    start = time.time()\n",
    "    num_class = 10\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    correct_top3_predictions = 0\n",
    "    total_samples = 0\n",
    "    confus = torch.zeros(num_class, num_class,dtype=int)            \n",
    "    for images, labels in tqdm(data_loader): # Iterate over data.\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        model_outputs = []\n",
    "        for model in model_list:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                model_outputs.append(outputs)\n",
    "        vote_outputs = majority_voting(model_outputs)\n",
    "        loss = criterion(vote_outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(vote_outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        _, top3_preds = vote_outputs.topk(3, 1, True, True)\n",
    "        correct_top3_predictions += sum([labels[i] in top3_preds[i] for i in range(labels.size(0))])\n",
    "\n",
    "        total_samples += labels.size(0)\n",
    "        for ii in range(len(predicted)):\n",
    "            confus[ labels.data[ii] ][ predicted[ii] ]+=1\n",
    "\n",
    "    avg_loss = running_loss / total_samples\n",
    "    top1_accuracy = correct_predictions / total_samples * 100\n",
    "    top3_accuracy = correct_top3_predictions / total_samples * 100\n",
    "    print(f\"samples: {total_samples}, Loss: {avg_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-3 Accuracy: {top3_accuracy:.2f}%\")\n",
    "    for ii in range(num_class) :\n",
    "        print(f\"class {ii}:{confus.numpy()[ii]}\")\n",
    "        # pprint(confus)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    print(f\"Elapsed time: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\Casper\\OTHER\\Data\\MNIST2\\HW2_MNIST_train\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "transform = transforms.Compose([])\n",
    "data_folder = path\n",
    "custom_dataset = CustomImageDataset(data_folder, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- INDEX checking ---------\n",
      "Original: [0, 1, 2, 3, 4]\n",
      "Shuffled: [41016, 92222, 13339, 16125, 7390]\n",
      "--------- INDEX shuffled ---------\n",
      "\n",
      "Total number of samples: 97396 datapoints\n",
      "Number of train samples: 0 batches/ 0 datapoints\n",
      "Number of val samples: 1522 batches/ 97396 datapoints\n",
      "Number of test samples: 0 batches/ 0 datapoints\n",
      "Data Transform: Compose(\n",
      ")\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1522/1522 [06:59<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 97396, Loss: 0.0000, Top-1 Accuracy: 99.96%, Top-3 Accuracy: 100.00%\n",
      "class 0:[10785     0     0     0     0     0     0     0     0     0]\n",
      "class 1:[    0 10830     0     0     0     0     0     5     0     0]\n",
      "class 2:[   0    0 9529    0    0    0    0    2    0    0]\n",
      "class 3:[   0    0    0 9810    0    1    0    1    0    0]\n",
      "class 4:[   0    0    0    0 9311    0    0    1    0    2]\n",
      "class 5:[   2    0    0    3    0 8680    1    0    1    0]\n",
      "class 6:[   0    0    0    0    2    0 9472    0    0    0]\n",
      "class 7:[    0     0     0     0     0     0     0 10007     0     0]\n",
      "class 8:[   0    0    1    1    0    2    0    0 9422    1]\n",
      "class 9:[   0    0    0    0    9    1    0    5    0 9509]\n",
      "Elapsed time: 419.2192018032074 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loaders2_1_1 = get_dataloaders(data_folder, transform, 0, 1, 64)\n",
    "\n",
    "path = \"D:\\\\Casper\\\\aML\\\\HW2\\\\\"\n",
    "path2 = \"D:\\\\Casper\\\\aML\\\\HW2\\\\aML\\\\\"\n",
    "path = \"D:\\\\Casper\\\\OTHER\\\\Weight\\\\aML\\\\\"\n",
    "model_list = [\n",
    "    torch.jit.load(f'{path}resnet152_hw1_99.87268470984435.pt'),\n",
    "    torch.jit.load(f'{path}resnet152_hw1_99.7576902542199.pt'),\n",
    "    torch.jit.load(f'{path}resnet152_hw1_99.8398291510945.pt'),\n",
    "    torch.jit.load(f'{path}resnet152_hw1_99.79362602160253.pt'),\n",
    "    torch.jit.load(f'{path}resnet152_hw1_99.81621421824305.pt'),\n",
    "    \n",
    "    torch.jit.load(f'{path}resnet152.pt'),\n",
    "    torch.jit.load(f'{path}resnet101.pt'),\n",
    "    torch.jit.load(f'{path}resnet50.pt'),\n",
    "    torch.jit.load(f'{path}resnet18.pt'),\n",
    "]\n",
    "\n",
    "eval(model_list, loaders2_1_1['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- INDEX checking ---------\n",
      "Original: [0, 1, 2, 3, 4]\n",
      "Shuffled: [57467, 32380, 11020, 93807, 59050]\n",
      "--------- INDEX shuffled ---------\n",
      "\n",
      "Total number of samples: 97396 datapoints\n",
      "Number of train samples: 97396 batches/ 97396 datapoints\n",
      "Number of val samples: 0 batches/ 0 datapoints\n",
      "Number of test samples: 0 batches/ 0 datapoints\n",
      "Data Transform: Compose(\n",
      ")\n",
      "\n",
      "Number of parameter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97396/97396 [01:04<00:00, 1511.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 20.61%\n",
      "score = 20.61275617068463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader2_1_2 = get_dataloaders(data_folder, transform, 1, 0.5, 1)\n",
    "model2_1_2 = torch.jit.load(f'D:\\\\Casper\\\\aML\\\\HW2\\\\OneParaModel.pt')\n",
    "\n",
    "def evaluation(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_of_para = count_parameters(model)\n",
    "    print(f\"Number of parameter: {num_of_para}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            outputs = model(inputs)\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Total accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"score = {accuracy*100/num_of_para}\")\n",
    "evaluation(model2_1_2, loader2_1_2['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2-1-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- INDEX checking ---------\n",
      "Original: [0, 1, 2, 3, 4]\n",
      "Shuffled: [0, 1, 2, 3, 4]\n",
      "--------- INDEX shuffled ---------\n",
      "\n",
      "Total number of samples: 24350 datapoints\n",
      "Number of train samples: 0 batches/ 0 datapoints\n",
      "Number of val samples: 24350 batches/ 24350 datapoints\n",
      "Number of test samples: 0 batches/ 0 datapoints\n",
      "Data Transform: Compose(\n",
      ")\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24350/24350 [11:24<00:00, 35.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict_images(data_loader, model, output_csv_path):\n",
    "    results = []\n",
    "    \n",
    "    for model in model_list:\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, image_name in tqdm(data_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            model_outputs = []\n",
    "            for model in model_list:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    model_outputs.append(outputs)\n",
    "            vote_outputs = majority_voting(model_outputs)\n",
    "            _, predicted = torch.max(vote_outputs, 1)\n",
    "            results.append([image_name[0], predicted.item()])\n",
    "            # break\n",
    "\n",
    "\n",
    "    with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['image', 'class'])  # Write the header\n",
    "        writer.writerows(results)\n",
    "\n",
    "folder_path = 'D:\\\\Casper\\\\OTHER\\\\Data\\\\MNIST2\\\\HW2_MNIST_test'\n",
    "output_csv_path = 'predictions.csv'\n",
    "\n",
    "path = \"D:\\\\Casper\\\\aML\\\\HW2\\\\\"\n",
    "path2 = \"D:\\\\Casper\\\\aML\\\\HW2\\\\aML\\\\\"\n",
    "model_list = [\n",
    "    torch.jit.load(f'{path}resnet152.pt'),\n",
    "    torch.jit.load(f'{path}resnet101.pt'),\n",
    "    torch.jit.load(f'{path}resnet50.pt'),\n",
    "    torch.jit.load(f'{path}resnet18.pt'),\n",
    "\n",
    "    torch.jit.load(f'{path2}R6_btnk_ch8(hw2).pt'),\n",
    "    torch.jit.load(f'{path2}R6_btnk_8ch4n8.pt'),\n",
    "]\n",
    "\n",
    "custom_dataset = CustomImageDataset_test(folder_path, transform)\n",
    "loader2_1_3 = get_dataloaders(folder_path, transform, 0, 1, 1, False, False)\n",
    "predict_images(loader2_1_3['val'], model_list, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
