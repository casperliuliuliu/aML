{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with respect to the first weight of fc: -16.440515518188477\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.fc = nn.Linear(4, 1, bias=False)  # Assuming the output of conv is flattened to 4 elements\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.conv(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleConvNet()\n",
    "\n",
    "# Define inputs\n",
    "input_feature_map = torch.randn(1, 1, 4, 4, requires_grad=True)  # Batch size of 1, 1 channel, 4x4 feature map\n",
    "true_label = torch.tensor([[17.]], requires_grad=False)  # Placeholder for 'yy'\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_feature_map)\n",
    "\n",
    "# Calculate the loss\n",
    "loss_fn = nn.MSELoss()\n",
    "loss = loss_fn(output, true_label)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Directly access the gradient of the first weight of the fc layer\n",
    "gradient_wrt_fc1 = model.fc.weight.grad[0][0]\n",
    "print(f\"Gradient with respect to the first weight of fc: {gradient_wrt_fc1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual gradient calculation of fc1's first weight: -25.68474769592285\n",
      "PyTorch gradient of fc1's first weight: -25.68474769592285\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Assuming model is your SimpleConvNet and has been defined and initialized\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Forward pass to get the activations right before the fc layer\n",
    "conv_output = F.sigmoid(model.conv(input_feature_map))\n",
    "conv_output_flattened = torch.flatten(conv_output, 1)\n",
    "\n",
    "# Manual calculation of the gradient of the first fc layer weight\n",
    "# Calculate dL/do = 2 * (o - y) since it's a single output node for MSE loss\n",
    "dL_do = 2 * (output - true_label)\n",
    "\n",
    "# The input to the fc layer's first weight is the corresponding element of the flattened conv output\n",
    "do_dw = conv_output_flattened[0][0]  # derivative of the output w.r.t. the weight is the input itself\n",
    "\n",
    "# Gradient w.r.t the first weight is the product of these derivatives\n",
    "gradient_wrt_fc1_manual = dL_do * do_dw\n",
    "\n",
    "print(f\"Manual gradient calculation of fc1's first weight: {gradient_wrt_fc1_manual.item()}\")\n",
    "\n",
    "# Compare with PyTorch's computed gradient\n",
    "print(f\"PyTorch gradient of fc1's first weight: {model.fc.weight.grad[0][0].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual gradient calculation of conv's weight[1][1]: 2.956057980656624\n",
      "PyTorch gradient of conv's weight[1][1]: 0.40257540345191956\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Assuming the model and inputs are already defined\n",
    "model.eval()  # Evaluation mode\n",
    "\n",
    "# Forward pass through the convolutional layer\n",
    "conv_output = model.conv(input_feature_map)\n",
    "sigmoid_output = F.sigmoid(conv_output)\n",
    "\n",
    "# Calculate the derivative of the loss w.r.t. the output\n",
    "dL_do = 2 * (output - true_label)\n",
    "\n",
    "# Forward pass through the rest of the network to get to the output\n",
    "conv_output_flattened = torch.flatten(sigmoid_output, 1)\n",
    "fc_output = model.fc(conv_output_flattened)\n",
    "\n",
    "# Now, calculate the gradient of `weight[1][1]` in the conv layer\n",
    "# Identify the contributions of weight[1][1] to the convolution output\n",
    "# Note: This requires understanding which input pixels affect weight[1][1]\n",
    "\n",
    "grad_w11 = 0\n",
    "for i in range(2):  # Assuming a 4x4 input, the kernel affects positions [1, 2] for both i and j\n",
    "    for j in range(2):\n",
    "        # Get the derivative of the sigmoid activation w.r.t. the conv output\n",
    "        dAct_dConv = sigmoid_prime(conv_output[0][0][i][j])\n",
    "        \n",
    "        # The input that corresponds to weight[1][1] for this position\n",
    "        input_contrib = input_feature_map[0][0][i+1][j+1]\n",
    "        \n",
    "        # Gradient contribution for this position\n",
    "        # Multiply by the derivative of the loss w.r.t. fc output (chain through fc weights)\n",
    "        for ii in range(4):\n",
    "            grad_w11 += (dL_do * model.fc.weight[0][ii] * dAct_dConv * input_contrib).item()\n",
    "\n",
    "# This is a simplified and not fully accurate calculation,\n",
    "# it illustrates the approach but skips over batch handling and complete chaining through the network\n",
    "print(f\"Manual gradient calculation of conv's weight[1][1]: {grad_w11}\")\n",
    "\n",
    "# Compare with PyTorch's computed gradient\n",
    "# model.zero_grad()\n",
    "loss.backward()\n",
    "print(f\"PyTorch gradient of conv's weight[1][1]: {model.conv.weight.grad[0][0][1][1].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
