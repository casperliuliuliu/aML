{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 10240)\n",
      "(750,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tdqm import tdqm\n",
    "# 讀取數據\n",
    "train_normal = np.load('Data/train_normal.npy')\n",
    "train_outer_break = np.load('Data/train_outer_break.npy')\n",
    "train_inner_break = np.load('Data/train_inner_break.npy')\n",
    "\n",
    "# 創建標籤\n",
    "labels_normal = np.zeros(len(train_normal))\n",
    "labels_outer_break = np.ones(len(train_outer_break))\n",
    "labels_inner_break = np.full(len(train_inner_break), 2)\n",
    "\n",
    "# 合併數據和標籤\n",
    "X_train = np.concatenate((train_normal, train_outer_break, train_inner_break), axis=0)\n",
    "y_train = np.concatenate((labels_normal, labels_outer_break, labels_inner_break), axis=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float).unsqueeze(1)  # Adding channel dimension\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Assuming classification task\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "batch_size = 1  # Adjust the batch size according to your needs and hardware capabilities\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VibrationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VibrationCNN, self).__init__()\n",
    "        # Assuming 1D Convolutional layers for sequence data\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # The size here might need adjustment based on the size after convolutions and pooling\n",
    "        # Calculating the size: As input is 10240, after 3 pooling layers, the size is 10240/(2^3) = 1280\n",
    "        self.fc1 = nn.Linear(128 * 1280, 512)\n",
    "        \n",
    "        # Final output layer for classification into classes\n",
    "        # Assuming your output is multi-class classification with C classes\n",
    "        self.fc2 = nn.Linear(512, 3)  # Replace C with the actual number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape is [batch_size, channels, sequence_length]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Adjust the number of pool operations according to your model architecture\n",
    "        # An additional pool operation as an example\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten for the fully connected layer\n",
    "        x = x.view(-1, 128 * 1280)  # Adjust the flattening size accordingly\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation, as nn.CrossEntropyLoss() includes softmax\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVibrationCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m      9\u001b[0m loaders \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loader,\n\u001b[0;32m     11\u001b[0m }\n\u001b[1;32m---> 12\u001b[0m \u001b[43mbase_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# model = VibrationCNN().cuda()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# criterion = nn.CrossEntropyLoss()\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters(), lr=0.001)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#         # break\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\u001b[39;00m\n",
      "File \u001b[1;32md:\\Casper\\aML\\HW3\\base_func.py:63\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model_lists, model_name, loaders, phases, save_weight)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model_lists, model_name, loaders, phases \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], save_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 63\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_lists\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m()\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m     65\u001b[0m         num_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import base_func \n",
    "model_list = {\n",
    "    \"VibrationCNN\" : lambda: VibrationCNN(),\n",
    "}\n",
    "model_name = [\n",
    "    \"VibrationCNN\",\n",
    "]\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "}\n",
    "base_func.train(model_list, model_name, loaders)\n",
    "# model = VibrationCNN().cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 假設你已經將X_train, y_train轉換成適當的PyTorch tensors和DataLoader\n",
    "\n",
    "# for epoch in range(10):  # 迭代次數\n",
    "#     for inputs, labels in tdqm(train_loader):\n",
    "#         inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         # print(outputs)\n",
    "#         # print(labels)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # break\n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
